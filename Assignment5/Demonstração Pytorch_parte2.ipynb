{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demonstração - Pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Um exemplo mais completo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carrega os dados e os separa em treino e teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([140, 3])\n",
      "torch.Size([140])\n",
      "torch.Size([60, 3])\n",
      "torch.Size([60])\n",
      "1\n",
      "torch.float64\n",
      "\n",
      "Depois da conversão para float e do reshape\n",
      "torch.float32\n",
      "torch.Size([140, 1])\n",
      "torch.Size([60, 1])\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "dfPropaganda = pd.read_csv('Advertising.csv',index_col=0)\n",
    "\n",
    "y= dfPropaganda.loc[:,'Sales']\n",
    "X = dfPropaganda.loc[:,['TV','Radio','Newspaper']]\n",
    "\n",
    "y_tensor = torch.tensor(y.to_numpy())\n",
    "X_tensor = torch.tensor(X.to_numpy())\n",
    "\n",
    "X_treino, X_teste, y_treino, y_teste = train_test_split(X_tensor, y_tensor, test_size = 0.30, random_state=5)\n",
    "\n",
    "print(X_treino.shape)\n",
    "print(y_treino.shape)\n",
    "\n",
    "print(X_teste.shape)\n",
    "print(y_teste.shape)\n",
    "print(y_teste.ndim)\n",
    "print(X_treino.dtype)\n",
    "\n",
    "#Manda para o dispositivo selecionado - no caso, GPU\n",
    "X_treino = X_treino.float().to(device)\n",
    "y_treino = y_treino.float().to(device)\n",
    "\n",
    "#reshape com -1: infere o valor com base no que está sendo passado (passo para sair de 1d e ir para 2d e evitar problemas de cálculos).\n",
    "y_treino = torch.reshape(y_treino, (-1,1))\n",
    "\n",
    "X_teste = X_teste.float().to(device)\n",
    "y_teste = y_teste.float().to(device)\n",
    "y_teste = torch.reshape(y_teste, (-1,1))\n",
    "\n",
    "print(\"\\nDepois da conversão para float e do reshape\")\n",
    "print(X_treino.dtype)\n",
    "print(y_treino.shape)\n",
    "print(y_teste.shape)\n",
    "print(y_teste.ndim)\n",
    "\n",
    "#Já convertemos para float, pois inicialmente o padrão é double'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementa uma classe com o modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para definir uma rede neural em PyTorch, criamos uma classe que herda de nn.Module. Definimos as camadas da rede na função __init__ e especificamos como os dados passarão pela rede na função forward. <br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Feedforward(torch.nn.Module):\n",
    "    \n",
    "        #Esta função é onde você define as camadas totalmente conectadas em sua rede neural\n",
    "        def __init__(self, input_size, hidden_size):\n",
    "            super(Feedforward, self).__init__()\n",
    "            \n",
    "            \n",
    "            self.input_size = input_size\n",
    "            self.hidden_size  = hidden_size\n",
    "            \n",
    "            self.fc1 = torch.nn.Linear(self.input_size, self.hidden_size)\n",
    "            self.fc2 = torch.nn.Linear(self.hidden_size, self.hidden_size)\n",
    "            self.fc3 = torch.nn.Linear(self.hidden_size, self.hidden_size)\n",
    "            self.fc4 = torch.nn.Linear(self.hidden_size, 1)\n",
    "            \n",
    "        \n",
    "        #Forward: Especifica como os dados passarão pelo seu modelo\n",
    "        #x representa nossos dados\n",
    "        def forward(self, x):\n",
    "            \n",
    "            output = self.fc1(x)\n",
    "            output = F.relu(output)\n",
    "            \n",
    "            \n",
    "            output = self.fc2(output)\n",
    "            output = F.relu(output)\n",
    "            \n",
    "            output = self.fc3(output)\n",
    "            output = F.relu(output)\n",
    "            \n",
    "            output = self.fc4(output)\n",
    "\n",
    "            return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo e critério de otimização\n",
    "Para acelerar as operações na rede neural, nós a movemos para a GPU, se disponível."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feedforward(\n",
      "  (fc1): Linear(in_features=3, out_features=10, bias=True)\n",
      "  (fc2): Linear(in_features=10, out_features=10, bias=True)\n",
      "  (fc3): Linear(in_features=10, out_features=10, bias=True)\n",
      "  (fc4): Linear(in_features=10, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "#input = 3 (número de features), e hidden size = 10 (número de neurôneos na camada escondida)\n",
    "model = Feedforward(3, 10).to(device)\n",
    "print(model)\n",
    "criterion = torch.nn.MSELoss()\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Treino e teste do modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Teste - perda antes do treinamento 162.53648376464844\n",
      "Epoch 0: perda treino: 165.1116485595703\n",
      "Epoch 1: perda treino: 162.56381225585938\n",
      "Epoch 2: perda treino: 159.9998321533203\n",
      "Epoch 3: perda treino: 157.4158477783203\n",
      "Epoch 4: perda treino: 154.81414794921875\n",
      "Epoch 5: perda treino: 152.19459533691406\n",
      "Epoch 6: perda treino: 149.5593719482422\n",
      "Epoch 7: perda treino: 146.9037322998047\n",
      "Epoch 8: perda treino: 144.23013305664062\n",
      "Epoch 9: perda treino: 141.53173828125\n",
      "Epoch 10: perda treino: 138.81961059570312\n",
      "Epoch 11: perda treino: 136.08837890625\n",
      "Epoch 12: perda treino: 133.3384246826172\n",
      "Epoch 13: perda treino: 130.57290649414062\n",
      "Epoch 14: perda treino: 127.79534149169922\n",
      "Epoch 15: perda treino: 125.00003051757812\n",
      "Epoch 16: perda treino: 122.19566345214844\n",
      "Epoch 17: perda treino: 119.38546752929688\n",
      "Epoch 18: perda treino: 116.57852935791016\n",
      "Epoch 19: perda treino: 113.76547241210938\n",
      "Epoch 20: perda treino: 110.95496368408203\n",
      "Epoch 21: perda treino: 108.14932250976562\n",
      "Epoch 22: perda treino: 105.34054565429688\n",
      "Epoch 23: perda treino: 102.52560424804688\n",
      "Epoch 24: perda treino: 99.7036361694336\n",
      "Epoch 25: perda treino: 96.87138366699219\n",
      "Epoch 26: perda treino: 94.01898956298828\n",
      "Epoch 27: perda treino: 91.16670989990234\n",
      "Epoch 28: perda treino: 88.31671142578125\n",
      "Epoch 29: perda treino: 85.45704650878906\n",
      "Epoch 30: perda treino: 82.5999526977539\n",
      "Epoch 31: perda treino: 79.74134063720703\n",
      "Epoch 32: perda treino: 76.89164733886719\n",
      "Epoch 33: perda treino: 74.05715942382812\n",
      "Epoch 34: perda treino: 71.2427749633789\n",
      "Epoch 35: perda treino: 68.45122528076172\n",
      "Epoch 36: perda treino: 65.6867904663086\n",
      "Epoch 37: perda treino: 62.95064163208008\n",
      "Epoch 38: perda treino: 60.26121520996094\n",
      "Epoch 39: perda treino: 57.614166259765625\n",
      "Epoch 40: perda treino: 55.02400207519531\n",
      "Epoch 41: perda treino: 52.49150466918945\n",
      "Epoch 42: perda treino: 50.02478790283203\n",
      "Epoch 43: perda treino: 47.642921447753906\n",
      "Epoch 44: perda treino: 45.34869384765625\n",
      "Epoch 45: perda treino: 43.15428924560547\n",
      "Epoch 46: perda treino: 41.050968170166016\n",
      "Epoch 47: perda treino: 39.070987701416016\n",
      "Epoch 48: perda treino: 37.22364807128906\n",
      "Epoch 49: perda treino: 35.52049255371094\n",
      "Epoch 50: perda treino: 33.96205520629883\n",
      "Epoch 51: perda treino: 32.554508209228516\n",
      "Epoch 52: perda treino: 31.29884147644043\n",
      "Epoch 53: perda treino: 30.196561813354492\n",
      "Epoch 54: perda treino: 29.244844436645508\n",
      "Epoch 55: perda treino: 28.427644729614258\n",
      "Epoch 56: perda treino: 27.738645553588867\n",
      "Epoch 57: perda treino: 27.16492462158203\n",
      "Epoch 58: perda treino: 26.692840576171875\n",
      "Epoch 59: perda treino: 26.3095760345459\n",
      "Epoch 60: perda treino: 26.004011154174805\n",
      "Epoch 61: perda treino: 25.75672721862793\n",
      "Epoch 62: perda treino: 25.550615310668945\n",
      "Epoch 63: perda treino: 25.372426986694336\n",
      "Epoch 64: perda treino: 25.20989990234375\n",
      "Epoch 65: perda treino: 25.058191299438477\n",
      "Epoch 66: perda treino: 24.908065795898438\n",
      "Epoch 67: perda treino: 24.761144638061523\n",
      "Epoch 68: perda treino: 24.617874145507812\n",
      "Epoch 69: perda treino: 24.46982192993164\n",
      "Epoch 70: perda treino: 24.29715919494629\n",
      "Epoch 71: perda treino: 24.103975296020508\n",
      "Epoch 72: perda treino: 23.892101287841797\n",
      "Epoch 73: perda treino: 23.6634521484375\n",
      "Epoch 74: perda treino: 23.420896530151367\n",
      "Epoch 75: perda treino: 23.165834426879883\n",
      "Epoch 76: perda treino: 22.899972915649414\n",
      "Epoch 77: perda treino: 22.628360748291016\n",
      "Epoch 78: perda treino: 22.356904983520508\n",
      "Epoch 79: perda treino: 22.08791160583496\n",
      "Epoch 80: perda treino: 21.82402229309082\n",
      "Epoch 81: perda treino: 21.56537628173828\n",
      "Epoch 82: perda treino: 21.31255531311035\n",
      "Epoch 83: perda treino: 21.067514419555664\n",
      "Epoch 84: perda treino: 20.829984664916992\n",
      "Epoch 85: perda treino: 20.59395980834961\n",
      "Epoch 86: perda treino: 20.357860565185547\n",
      "Epoch 87: perda treino: 20.11671257019043\n",
      "Epoch 88: perda treino: 19.871410369873047\n",
      "Epoch 89: perda treino: 19.61321449279785\n",
      "Epoch 90: perda treino: 19.331148147583008\n",
      "Epoch 91: perda treino: 19.035863876342773\n",
      "Epoch 92: perda treino: 18.74167823791504\n",
      "Epoch 93: perda treino: 18.472301483154297\n",
      "Epoch 94: perda treino: 18.246173858642578\n",
      "Epoch 95: perda treino: 18.04418182373047\n",
      "Epoch 96: perda treino: 17.84880256652832\n",
      "Epoch 97: perda treino: 17.660762786865234\n",
      "Epoch 98: perda treino: 17.474180221557617\n",
      "Epoch 99: perda treino: 17.287429809570312\n",
      "Epoch 100: perda treino: 17.10512351989746\n",
      "Epoch 101: perda treino: 16.948200225830078\n",
      "Epoch 102: perda treino: 16.79689598083496\n",
      "Epoch 103: perda treino: 16.645156860351562\n",
      "Epoch 104: perda treino: 16.485883712768555\n",
      "Epoch 105: perda treino: 16.316951751708984\n",
      "Epoch 106: perda treino: 16.14319610595703\n",
      "Epoch 107: perda treino: 15.977288246154785\n",
      "Epoch 108: perda treino: 15.818272590637207\n",
      "Epoch 109: perda treino: 15.682766914367676\n",
      "Epoch 110: perda treino: 15.550939559936523\n",
      "Epoch 111: perda treino: 15.416866302490234\n",
      "Epoch 112: perda treino: 15.278976440429688\n",
      "Epoch 113: perda treino: 15.141840934753418\n",
      "Epoch 114: perda treino: 15.00653076171875\n",
      "Epoch 115: perda treino: 14.87244701385498\n",
      "Epoch 116: perda treino: 14.740989685058594\n",
      "Epoch 117: perda treino: 14.60934066772461\n",
      "Epoch 118: perda treino: 14.477349281311035\n",
      "Epoch 119: perda treino: 14.342456817626953\n",
      "Epoch 120: perda treino: 14.210508346557617\n",
      "Epoch 121: perda treino: 14.082621574401855\n",
      "Epoch 122: perda treino: 13.951123237609863\n",
      "Epoch 123: perda treino: 13.820740699768066\n",
      "Epoch 124: perda treino: 13.695089340209961\n",
      "Epoch 125: perda treino: 13.57125473022461\n",
      "Epoch 126: perda treino: 13.449271202087402\n",
      "Epoch 127: perda treino: 13.333979606628418\n",
      "Epoch 128: perda treino: 13.220831871032715\n",
      "Epoch 129: perda treino: 13.108759880065918\n",
      "Epoch 130: perda treino: 12.997594833374023\n",
      "Epoch 131: perda treino: 12.885663986206055\n",
      "Epoch 132: perda treino: 12.775687217712402\n",
      "Epoch 133: perda treino: 12.667642593383789\n",
      "Epoch 134: perda treino: 12.558032989501953\n",
      "Epoch 135: perda treino: 12.447608947753906\n",
      "Epoch 136: perda treino: 12.339127540588379\n",
      "Epoch 137: perda treino: 12.232686042785645\n",
      "Epoch 138: perda treino: 12.122331619262695\n",
      "Epoch 139: perda treino: 12.010320663452148\n",
      "Epoch 140: perda treino: 11.896820068359375\n",
      "Epoch 141: perda treino: 11.781682968139648\n",
      "Epoch 142: perda treino: 11.666406631469727\n",
      "Epoch 143: perda treino: 11.5569486618042\n",
      "Epoch 144: perda treino: 11.451571464538574\n",
      "Epoch 145: perda treino: 11.350690841674805\n",
      "Epoch 146: perda treino: 11.254657745361328\n",
      "Epoch 147: perda treino: 11.156121253967285\n",
      "Epoch 148: perda treino: 11.057318687438965\n",
      "Epoch 149: perda treino: 10.957747459411621\n",
      "Epoch 150: perda treino: 10.859594345092773\n",
      "Epoch 151: perda treino: 10.763919830322266\n",
      "Epoch 152: perda treino: 10.67156982421875\n",
      "Epoch 153: perda treino: 10.582788467407227\n",
      "Epoch 154: perda treino: 10.496740341186523\n",
      "Epoch 155: perda treino: 10.412420272827148\n",
      "Epoch 156: perda treino: 10.326944351196289\n",
      "Epoch 157: perda treino: 10.241109848022461\n",
      "Epoch 158: perda treino: 10.157901763916016\n",
      "Epoch 159: perda treino: 10.077539443969727\n",
      "Epoch 160: perda treino: 9.999109268188477\n",
      "Epoch 161: perda treino: 9.920574188232422\n",
      "Epoch 162: perda treino: 9.842903137207031\n",
      "Epoch 163: perda treino: 9.765974044799805\n",
      "Epoch 164: perda treino: 9.689871788024902\n",
      "Epoch 165: perda treino: 9.615857124328613\n",
      "Epoch 166: perda treino: 9.544370651245117\n",
      "Epoch 167: perda treino: 9.473333358764648\n",
      "Epoch 168: perda treino: 9.402634620666504\n",
      "Epoch 169: perda treino: 9.3319730758667\n",
      "Epoch 170: perda treino: 9.261299133300781\n",
      "Epoch 171: perda treino: 9.192131996154785\n",
      "Epoch 172: perda treino: 9.125269889831543\n",
      "Epoch 173: perda treino: 9.059154510498047\n",
      "Epoch 174: perda treino: 8.993459701538086\n",
      "Epoch 175: perda treino: 8.927122116088867\n",
      "Epoch 176: perda treino: 8.860595703125\n",
      "Epoch 177: perda treino: 8.794402122497559\n",
      "Epoch 178: perda treino: 8.728096961975098\n",
      "Epoch 179: perda treino: 8.66072940826416\n",
      "Epoch 180: perda treino: 8.59305191040039\n",
      "Epoch 181: perda treino: 8.525312423706055\n",
      "Epoch 182: perda treino: 8.45628833770752\n",
      "Epoch 183: perda treino: 8.386685371398926\n",
      "Epoch 184: perda treino: 8.314988136291504\n",
      "Epoch 185: perda treino: 8.243220329284668\n",
      "Epoch 186: perda treino: 8.171828269958496\n",
      "Epoch 187: perda treino: 8.101539611816406\n",
      "Epoch 188: perda treino: 8.031407356262207\n",
      "Epoch 189: perda treino: 7.961143493652344\n",
      "Epoch 190: perda treino: 7.892388820648193\n",
      "Epoch 191: perda treino: 7.8234453201293945\n",
      "Epoch 192: perda treino: 7.7544331550598145\n",
      "Epoch 193: perda treino: 7.687720775604248\n",
      "Epoch 194: perda treino: 7.621368408203125\n",
      "Epoch 195: perda treino: 7.554994583129883\n",
      "Epoch 196: perda treino: 7.488630294799805\n",
      "Epoch 197: perda treino: 7.423901557922363\n",
      "Epoch 198: perda treino: 7.360421180725098\n",
      "Epoch 199: perda treino: 7.297090530395508\n",
      "Epoch 200: perda treino: 7.233835220336914\n",
      "Epoch 201: perda treino: 7.168990612030029\n",
      "Epoch 202: perda treino: 7.105138301849365\n",
      "Epoch 203: perda treino: 7.041759490966797\n",
      "Epoch 204: perda treino: 6.979426860809326\n",
      "Epoch 205: perda treino: 6.915098190307617\n",
      "Epoch 206: perda treino: 6.849429607391357\n",
      "Epoch 207: perda treino: 6.784461498260498\n",
      "Epoch 208: perda treino: 6.719583034515381\n",
      "Epoch 209: perda treino: 6.655983924865723\n",
      "Epoch 210: perda treino: 6.592848777770996\n",
      "Epoch 211: perda treino: 6.528730392456055\n",
      "Epoch 212: perda treino: 6.465025424957275\n",
      "Epoch 213: perda treino: 6.403966426849365\n",
      "Epoch 214: perda treino: 6.344780921936035\n",
      "Epoch 215: perda treino: 6.285619258880615\n",
      "Epoch 216: perda treino: 6.22878885269165\n",
      "Epoch 217: perda treino: 6.173066139221191\n",
      "Epoch 218: perda treino: 6.116700649261475\n",
      "Epoch 219: perda treino: 6.061600208282471\n",
      "Epoch 220: perda treino: 6.007298946380615\n",
      "Epoch 221: perda treino: 5.952945709228516\n",
      "Epoch 222: perda treino: 5.898879528045654\n",
      "Epoch 223: perda treino: 5.845843315124512\n",
      "Epoch 224: perda treino: 5.793661594390869\n",
      "Epoch 225: perda treino: 5.741962432861328\n",
      "Epoch 226: perda treino: 5.6909565925598145\n",
      "Epoch 227: perda treino: 5.640390396118164\n",
      "Epoch 228: perda treino: 5.590540885925293\n",
      "Epoch 229: perda treino: 5.540756702423096\n",
      "Epoch 230: perda treino: 5.491836071014404\n",
      "Epoch 231: perda treino: 5.440516471862793\n",
      "Epoch 232: perda treino: 5.387540817260742\n",
      "Epoch 233: perda treino: 5.3348517417907715\n",
      "Epoch 234: perda treino: 5.280573844909668\n",
      "Epoch 235: perda treino: 5.219590187072754\n",
      "Epoch 236: perda treino: 5.156529903411865\n",
      "Epoch 237: perda treino: 5.088395118713379\n",
      "Epoch 238: perda treino: 5.020727634429932\n",
      "Epoch 239: perda treino: 4.952169418334961\n",
      "Epoch 240: perda treino: 4.882159233093262\n",
      "Epoch 241: perda treino: 4.802642345428467\n",
      "Epoch 242: perda treino: 4.720107555389404\n",
      "Epoch 243: perda treino: 4.634684085845947\n",
      "Epoch 244: perda treino: 4.53562593460083\n",
      "Epoch 245: perda treino: 4.426466464996338\n",
      "Epoch 246: perda treino: 4.312061309814453\n",
      "Epoch 247: perda treino: 4.1808271408081055\n",
      "Epoch 248: perda treino: 4.043642044067383\n",
      "Epoch 249: perda treino: 3.911266326904297\n",
      "Epoch 250: perda treino: 3.782719612121582\n",
      "Epoch 251: perda treino: 3.6607155799865723\n",
      "Epoch 252: perda treino: 3.548800230026245\n",
      "Epoch 253: perda treino: 3.445993185043335\n",
      "Epoch 254: perda treino: 3.3675737380981445\n",
      "Epoch 255: perda treino: 3.3118906021118164\n",
      "Epoch 256: perda treino: 3.2686715126037598\n",
      "Epoch 257: perda treino: 3.24637508392334\n",
      "Epoch 258: perda treino: 3.231203556060791\n",
      "Epoch 259: perda treino: 3.2233431339263916\n",
      "Epoch 260: perda treino: 3.210615396499634\n",
      "Epoch 261: perda treino: 3.1946816444396973\n",
      "Epoch 262: perda treino: 3.176060676574707\n",
      "Epoch 263: perda treino: 3.1534786224365234\n",
      "Epoch 264: perda treino: 3.1260013580322266\n",
      "Epoch 265: perda treino: 3.0941619873046875\n",
      "Epoch 266: perda treino: 3.061462640762329\n",
      "Epoch 267: perda treino: 3.033024311065674\n",
      "Epoch 268: perda treino: 3.0063915252685547\n",
      "Epoch 269: perda treino: 2.981776237487793\n",
      "Epoch 270: perda treino: 2.9596915245056152\n",
      "Epoch 271: perda treino: 2.940089225769043\n",
      "Epoch 272: perda treino: 2.919874906539917\n",
      "Epoch 273: perda treino: 2.8986096382141113\n",
      "Epoch 274: perda treino: 2.8796579837799072\n",
      "Epoch 275: perda treino: 2.862841844558716\n",
      "Epoch 276: perda treino: 2.846358299255371\n",
      "Epoch 277: perda treino: 2.8283660411834717\n",
      "Epoch 278: perda treino: 2.811175584793091\n",
      "Epoch 279: perda treino: 2.796924114227295\n",
      "Epoch 280: perda treino: 2.783371925354004\n",
      "Epoch 281: perda treino: 2.7680180072784424\n",
      "Epoch 282: perda treino: 2.752368211746216\n",
      "Epoch 283: perda treino: 2.738903760910034\n",
      "Epoch 284: perda treino: 2.726958990097046\n",
      "Epoch 285: perda treino: 2.713916063308716\n",
      "Epoch 286: perda treino: 2.699995756149292\n",
      "Epoch 287: perda treino: 2.6870250701904297\n",
      "Epoch 288: perda treino: 2.6753618717193604\n",
      "Epoch 289: perda treino: 2.663278341293335\n",
      "Epoch 290: perda treino: 2.650285243988037\n",
      "Epoch 291: perda treino: 2.637906551361084\n",
      "Epoch 292: perda treino: 2.6268389225006104\n",
      "Epoch 293: perda treino: 2.6158289909362793\n",
      "Epoch 294: perda treino: 2.603982448577881\n",
      "Epoch 295: perda treino: 2.5925259590148926\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 296: perda treino: 2.5820472240448\n",
      "Epoch 297: perda treino: 2.571320056915283\n",
      "Epoch 298: perda treino: 2.5601847171783447\n",
      "Epoch 299: perda treino: 2.549793243408203\n",
      "Epoch 300: perda treino: 2.539794683456421\n",
      "Epoch 301: perda treino: 2.529709815979004\n",
      "Epoch 302: perda treino: 2.519573450088501\n",
      "Epoch 303: perda treino: 2.5104167461395264\n",
      "Epoch 304: perda treino: 2.501518964767456\n",
      "Epoch 305: perda treino: 2.492147445678711\n",
      "Epoch 306: perda treino: 2.4832751750946045\n",
      "Epoch 307: perda treino: 2.474832057952881\n",
      "Epoch 308: perda treino: 2.4662892818450928\n",
      "Epoch 309: perda treino: 2.457653045654297\n",
      "Epoch 310: perda treino: 2.449505567550659\n",
      "Epoch 311: perda treino: 2.441560745239258\n",
      "Epoch 312: perda treino: 2.433539628982544\n",
      "Epoch 313: perda treino: 2.4259250164031982\n",
      "Epoch 314: perda treino: 2.4181108474731445\n",
      "Epoch 315: perda treino: 2.410048484802246\n",
      "Epoch 316: perda treino: 2.401942729949951\n",
      "Epoch 317: perda treino: 2.3940470218658447\n",
      "Epoch 318: perda treino: 2.3863914012908936\n",
      "Epoch 319: perda treino: 2.3791916370391846\n",
      "Epoch 320: perda treino: 2.3721835613250732\n",
      "Epoch 321: perda treino: 2.36513352394104\n",
      "Epoch 322: perda treino: 2.358058214187622\n",
      "Epoch 323: perda treino: 2.3509557247161865\n",
      "Epoch 324: perda treino: 2.343829870223999\n",
      "Epoch 325: perda treino: 2.337070941925049\n",
      "Epoch 326: perda treino: 2.330286979675293\n",
      "Epoch 327: perda treino: 2.3235299587249756\n",
      "Epoch 328: perda treino: 2.3167848587036133\n",
      "Epoch 329: perda treino: 2.31010365486145\n",
      "Epoch 330: perda treino: 2.3035929203033447\n",
      "Epoch 331: perda treino: 2.297031879425049\n",
      "Epoch 332: perda treino: 2.291102409362793\n",
      "Epoch 333: perda treino: 2.2848269939422607\n",
      "Epoch 334: perda treino: 2.2783398628234863\n",
      "Epoch 335: perda treino: 2.2725956439971924\n",
      "Epoch 336: perda treino: 2.2662405967712402\n",
      "Epoch 337: perda treino: 2.260080099105835\n",
      "Epoch 338: perda treino: 2.253856897354126\n",
      "Epoch 339: perda treino: 2.2475829124450684\n",
      "Epoch 340: perda treino: 2.2416043281555176\n",
      "Epoch 341: perda treino: 2.2356207370758057\n",
      "Epoch 342: perda treino: 2.2293148040771484\n",
      "Epoch 343: perda treino: 2.2233026027679443\n",
      "Epoch 344: perda treino: 2.2167179584503174\n",
      "Epoch 345: perda treino: 2.210423231124878\n",
      "Epoch 346: perda treino: 2.2041218280792236\n",
      "Epoch 347: perda treino: 2.1975908279418945\n",
      "Epoch 348: perda treino: 2.191368818283081\n",
      "Epoch 349: perda treino: 2.1853435039520264\n",
      "Epoch 350: perda treino: 2.179351806640625\n",
      "Epoch 351: perda treino: 2.1732559204101562\n",
      "Epoch 352: perda treino: 2.1670825481414795\n",
      "Epoch 353: perda treino: 2.161109209060669\n",
      "Epoch 354: perda treino: 2.1552038192749023\n",
      "Epoch 355: perda treino: 2.1493418216705322\n",
      "Epoch 356: perda treino: 2.1437525749206543\n",
      "Epoch 357: perda treino: 2.1380271911621094\n",
      "Epoch 358: perda treino: 2.1325435638427734\n",
      "Epoch 359: perda treino: 2.1266729831695557\n",
      "Epoch 360: perda treino: 2.1211984157562256\n",
      "Epoch 361: perda treino: 2.1156721115112305\n",
      "Epoch 362: perda treino: 2.110352039337158\n",
      "Epoch 363: perda treino: 2.1046652793884277\n",
      "Epoch 364: perda treino: 2.0993220806121826\n",
      "Epoch 365: perda treino: 2.093916177749634\n",
      "Epoch 366: perda treino: 2.0883169174194336\n",
      "Epoch 367: perda treino: 2.083122491836548\n",
      "Epoch 368: perda treino: 2.077784776687622\n",
      "Epoch 369: perda treino: 2.0724658966064453\n",
      "Epoch 370: perda treino: 2.068178415298462\n",
      "Epoch 371: perda treino: 2.062657594680786\n",
      "Epoch 372: perda treino: 2.0580992698669434\n",
      "Epoch 373: perda treino: 2.0534121990203857\n",
      "Epoch 374: perda treino: 2.0483920574188232\n",
      "Epoch 375: perda treino: 2.0437238216400146\n",
      "Epoch 376: perda treino: 2.03914737701416\n",
      "Epoch 377: perda treino: 2.034271001815796\n",
      "Epoch 378: perda treino: 2.029510736465454\n",
      "Epoch 379: perda treino: 2.0249509811401367\n",
      "Epoch 380: perda treino: 2.0202527046203613\n",
      "Epoch 381: perda treino: 2.0155599117279053\n",
      "Epoch 382: perda treino: 2.011237144470215\n",
      "Epoch 383: perda treino: 2.006666898727417\n",
      "Epoch 384: perda treino: 2.002472400665283\n",
      "Epoch 385: perda treino: 1.9979339838027954\n",
      "Epoch 386: perda treino: 1.9938254356384277\n",
      "Epoch 387: perda treino: 1.989227533340454\n",
      "Epoch 388: perda treino: 1.9849892854690552\n",
      "Epoch 389: perda treino: 1.9805668592453003\n",
      "Epoch 390: perda treino: 1.976293683052063\n",
      "Epoch 391: perda treino: 1.9719593524932861\n",
      "Epoch 392: perda treino: 1.9676663875579834\n",
      "Epoch 393: perda treino: 1.963469386100769\n",
      "Epoch 394: perda treino: 1.9592211246490479\n",
      "Epoch 395: perda treino: 1.9551562070846558\n",
      "Epoch 396: perda treino: 1.9508841037750244\n",
      "Epoch 397: perda treino: 1.9466609954833984\n",
      "Epoch 398: perda treino: 1.9426801204681396\n",
      "Epoch 399: perda treino: 1.9384368658065796\n",
      "Epoch 400: perda treino: 1.9343940019607544\n",
      "Epoch 401: perda treino: 1.9303746223449707\n",
      "Epoch 402: perda treino: 1.9262497425079346\n",
      "Epoch 403: perda treino: 1.9221946001052856\n",
      "Epoch 404: perda treino: 1.918339729309082\n",
      "Epoch 405: perda treino: 1.914217233657837\n",
      "Epoch 406: perda treino: 1.9104108810424805\n",
      "Epoch 407: perda treino: 1.9063509702682495\n",
      "Epoch 408: perda treino: 1.9024678468704224\n",
      "Epoch 409: perda treino: 1.8985068798065186\n",
      "Epoch 410: perda treino: 1.8946866989135742\n",
      "Epoch 411: perda treino: 1.8907217979431152\n",
      "Epoch 412: perda treino: 1.8868399858474731\n",
      "Epoch 413: perda treino: 1.8832281827926636\n",
      "Epoch 414: perda treino: 1.8792803287506104\n",
      "Epoch 415: perda treino: 1.8758492469787598\n",
      "Epoch 416: perda treino: 1.8717135190963745\n",
      "Epoch 417: perda treino: 1.8677538633346558\n",
      "Epoch 418: perda treino: 1.8642778396606445\n",
      "Epoch 419: perda treino: 1.8603639602661133\n",
      "Epoch 420: perda treino: 1.8563824892044067\n",
      "Epoch 421: perda treino: 1.8528324365615845\n",
      "Epoch 422: perda treino: 1.8490657806396484\n",
      "Epoch 423: perda treino: 1.8451178073883057\n",
      "Epoch 424: perda treino: 1.8418081998825073\n",
      "Epoch 425: perda treino: 1.8380697965621948\n",
      "Epoch 426: perda treino: 1.8347586393356323\n",
      "Epoch 427: perda treino: 1.8313250541687012\n",
      "Epoch 428: perda treino: 1.8276965618133545\n",
      "Epoch 429: perda treino: 1.824701189994812\n",
      "Epoch 430: perda treino: 1.8209260702133179\n",
      "Epoch 431: perda treino: 1.8177571296691895\n",
      "Epoch 432: perda treino: 1.8142893314361572\n",
      "Epoch 433: perda treino: 1.8104405403137207\n",
      "Epoch 434: perda treino: 1.8079099655151367\n",
      "Epoch 435: perda treino: 1.8039088249206543\n",
      "Epoch 436: perda treino: 1.8013086318969727\n",
      "Epoch 437: perda treino: 1.7973339557647705\n",
      "Epoch 438: perda treino: 1.793728232383728\n",
      "Epoch 439: perda treino: 1.7909198999404907\n",
      "Epoch 440: perda treino: 1.7872283458709717\n",
      "Epoch 441: perda treino: 1.7835866212844849\n",
      "Epoch 442: perda treino: 1.780705213546753\n",
      "Epoch 443: perda treino: 1.777195692062378\n",
      "Epoch 444: perda treino: 1.7735751867294312\n",
      "Epoch 445: perda treino: 1.7705495357513428\n",
      "Epoch 446: perda treino: 1.7671363353729248\n",
      "Epoch 447: perda treino: 1.763639211654663\n",
      "Epoch 448: perda treino: 1.7605677843093872\n",
      "Epoch 449: perda treino: 1.7571570873260498\n",
      "Epoch 450: perda treino: 1.7537777423858643\n",
      "Epoch 451: perda treino: 1.7505823373794556\n",
      "Epoch 452: perda treino: 1.747219204902649\n",
      "Epoch 453: perda treino: 1.743844985961914\n",
      "Epoch 454: perda treino: 1.7406558990478516\n",
      "Epoch 455: perda treino: 1.7373591661453247\n",
      "Epoch 456: perda treino: 1.7340242862701416\n",
      "Epoch 457: perda treino: 1.7307941913604736\n",
      "Epoch 458: perda treino: 1.727479100227356\n",
      "Epoch 459: perda treino: 1.7241523265838623\n",
      "Epoch 460: perda treino: 1.720931053161621\n",
      "Epoch 461: perda treino: 1.7176594734191895\n",
      "Epoch 462: perda treino: 1.714691400527954\n",
      "Epoch 463: perda treino: 1.7114540338516235\n",
      "Epoch 464: perda treino: 1.708238959312439\n",
      "Epoch 465: perda treino: 1.7046961784362793\n",
      "Epoch 466: perda treino: 1.7017309665679932\n",
      "Epoch 467: perda treino: 1.698346734046936\n",
      "Epoch 468: perda treino: 1.6955339908599854\n",
      "Epoch 469: perda treino: 1.6920377016067505\n",
      "Epoch 470: perda treino: 1.6888072490692139\n",
      "Epoch 471: perda treino: 1.6858494281768799\n",
      "Epoch 472: perda treino: 1.6824016571044922\n",
      "Epoch 473: perda treino: 1.6791754961013794\n",
      "Epoch 474: perda treino: 1.6761131286621094\n",
      "Epoch 475: perda treino: 1.6727044582366943\n",
      "Epoch 476: perda treino: 1.6695235967636108\n",
      "Epoch 477: perda treino: 1.6664239168167114\n",
      "Epoch 478: perda treino: 1.6630810499191284\n",
      "Epoch 479: perda treino: 1.6599254608154297\n",
      "Epoch 480: perda treino: 1.656775951385498\n",
      "Epoch 481: perda treino: 1.6534686088562012\n",
      "Epoch 482: perda treino: 1.6503206491470337\n",
      "Epoch 483: perda treino: 1.6471422910690308\n",
      "Epoch 484: perda treino: 1.6438732147216797\n",
      "Epoch 485: perda treino: 1.640729308128357\n",
      "Epoch 486: perda treino: 1.6375365257263184\n",
      "Epoch 487: perda treino: 1.6342999935150146\n",
      "Epoch 488: perda treino: 1.6311800479888916\n",
      "Epoch 489: perda treino: 1.6280977725982666\n",
      "Epoch 490: perda treino: 1.6254805326461792\n",
      "Epoch 491: perda treino: 1.622398853302002\n",
      "Epoch 492: perda treino: 1.618548035621643\n",
      "Epoch 493: perda treino: 1.616220235824585\n",
      "Epoch 494: perda treino: 1.612310767173767\n",
      "Epoch 495: perda treino: 1.6097807884216309\n",
      "Epoch 496: perda treino: 1.6064012050628662\n",
      "Epoch 497: perda treino: 1.6029717922210693\n",
      "Epoch 498: perda treino: 1.600277066230774\n",
      "Epoch 499: perda treino: 1.596836805343628\n",
      "Epoch 500: perda treino: 1.5936251878738403\n",
      "Epoch 501: perda treino: 1.590762734413147\n",
      "Epoch 502: perda treino: 1.587314248085022\n",
      "Epoch 503: perda treino: 1.5842574834823608\n",
      "Epoch 504: perda treino: 1.5812664031982422\n",
      "Epoch 505: perda treino: 1.5778896808624268\n",
      "Epoch 506: perda treino: 1.5749019384384155\n",
      "Epoch 507: perda treino: 1.5717706680297852\n",
      "Epoch 508: perda treino: 1.5684971809387207\n",
      "Epoch 509: perda treino: 1.5655232667922974\n",
      "Epoch 510: perda treino: 1.562321424484253\n",
      "Epoch 511: perda treino: 1.5591652393341064\n",
      "Epoch 512: perda treino: 1.5561518669128418\n",
      "Epoch 513: perda treino: 1.5529563426971436\n",
      "Epoch 514: perda treino: 1.5498524904251099\n",
      "Epoch 515: perda treino: 1.5467861890792847\n",
      "Epoch 516: perda treino: 1.5436228513717651\n",
      "Epoch 517: perda treino: 1.5405586957931519\n",
      "Epoch 518: perda treino: 1.5374534130096436\n",
      "Epoch 519: perda treino: 1.534691572189331\n",
      "Epoch 520: perda treino: 1.531761884689331\n",
      "Epoch 521: perda treino: 1.5285017490386963\n",
      "Epoch 522: perda treino: 1.5257939100265503\n",
      "Epoch 523: perda treino: 1.5223618745803833\n",
      "Epoch 524: perda treino: 1.519506812095642\n",
      "Epoch 525: perda treino: 1.5161850452423096\n",
      "Epoch 526: perda treino: 1.5134282112121582\n",
      "Epoch 527: perda treino: 1.5101959705352783\n",
      "Epoch 528: perda treino: 1.507170557975769\n",
      "Epoch 529: perda treino: 1.504093885421753\n",
      "Epoch 530: perda treino: 1.5009468793869019\n",
      "Epoch 531: perda treino: 1.4980664253234863\n",
      "Epoch 532: perda treino: 1.4948643445968628\n",
      "Epoch 533: perda treino: 1.4916115999221802\n",
      "Epoch 534: perda treino: 1.4884977340698242\n",
      "Epoch 535: perda treino: 1.485050082206726\n",
      "Epoch 536: perda treino: 1.4817949533462524\n",
      "Epoch 537: perda treino: 1.4787384271621704\n",
      "Epoch 538: perda treino: 1.475793719291687\n",
      "Epoch 539: perda treino: 1.4726632833480835\n",
      "Epoch 540: perda treino: 1.4686412811279297\n",
      "Epoch 541: perda treino: 1.466645359992981\n",
      "Epoch 542: perda treino: 1.4622926712036133\n",
      "Epoch 543: perda treino: 1.459930419921875\n",
      "Epoch 544: perda treino: 1.4559446573257446\n",
      "Epoch 545: perda treino: 1.453012228012085\n",
      "Epoch 546: perda treino: 1.4500409364700317\n",
      "Epoch 547: perda treino: 1.4463183879852295\n",
      "Epoch 548: perda treino: 1.4436113834381104\n",
      "Epoch 549: perda treino: 1.4401851892471313\n",
      "Epoch 550: perda treino: 1.4368253946304321\n",
      "Epoch 551: perda treino: 1.4339021444320679\n",
      "Epoch 552: perda treino: 1.4303779602050781\n",
      "Epoch 553: perda treino: 1.4275656938552856\n",
      "Epoch 554: perda treino: 1.4240683317184448\n",
      "Epoch 555: perda treino: 1.4211885929107666\n",
      "Epoch 556: perda treino: 1.4179751873016357\n",
      "Epoch 557: perda treino: 1.4146654605865479\n",
      "Epoch 558: perda treino: 1.4116287231445312\n",
      "Epoch 559: perda treino: 1.4084872007369995\n",
      "Epoch 560: perda treino: 1.4053263664245605\n",
      "Epoch 561: perda treino: 1.402105450630188\n",
      "Epoch 562: perda treino: 1.3987387418746948\n",
      "Epoch 563: perda treino: 1.395513653755188\n",
      "Epoch 564: perda treino: 1.3920364379882812\n",
      "Epoch 565: perda treino: 1.3888620138168335\n",
      "Epoch 566: perda treino: 1.3854814767837524\n",
      "Epoch 567: perda treino: 1.3821935653686523\n",
      "Epoch 568: perda treino: 1.3790943622589111\n",
      "Epoch 569: perda treino: 1.3762943744659424\n",
      "Epoch 570: perda treino: 1.3729815483093262\n",
      "Epoch 571: perda treino: 1.369267463684082\n",
      "Epoch 572: perda treino: 1.3666648864746094\n",
      "Epoch 573: perda treino: 1.3625288009643555\n",
      "Epoch 574: perda treino: 1.3594908714294434\n",
      "Epoch 575: perda treino: 1.356135368347168\n",
      "Epoch 576: perda treino: 1.3523019552230835\n",
      "Epoch 577: perda treino: 1.3496983051300049\n",
      "Epoch 578: perda treino: 1.3456428050994873\n",
      "Epoch 579: perda treino: 1.343170404434204\n",
      "Epoch 580: perda treino: 1.3383705615997314\n",
      "Epoch 581: perda treino: 1.3357192277908325\n",
      "Epoch 582: perda treino: 1.3307512998580933\n",
      "Epoch 583: perda treino: 1.3286546468734741\n",
      "Epoch 584: perda treino: 1.3233362436294556\n",
      "Epoch 585: perda treino: 1.3206719160079956\n",
      "Epoch 586: perda treino: 1.3159668445587158\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 587: perda treino: 1.3128864765167236\n",
      "Epoch 588: perda treino: 1.3097063302993774\n",
      "Epoch 589: perda treino: 1.3061543703079224\n",
      "Epoch 590: perda treino: 1.3020429611206055\n",
      "Epoch 591: perda treino: 1.298601508140564\n",
      "Epoch 592: perda treino: 1.2950336933135986\n",
      "Epoch 593: perda treino: 1.2912155389785767\n",
      "Epoch 594: perda treino: 1.2876416444778442\n",
      "Epoch 595: perda treino: 1.2841469049453735\n",
      "Epoch 596: perda treino: 1.280950665473938\n",
      "Epoch 597: perda treino: 1.2775447368621826\n",
      "Epoch 598: perda treino: 1.2740744352340698\n",
      "Epoch 599: perda treino: 1.2706279754638672\n",
      "Epoch 600: perda treino: 1.2672464847564697\n",
      "Epoch 601: perda treino: 1.263906717300415\n",
      "Epoch 602: perda treino: 1.260399580001831\n",
      "Epoch 603: perda treino: 1.2569527626037598\n",
      "Epoch 604: perda treino: 1.253549337387085\n",
      "Epoch 605: perda treino: 1.2502951622009277\n",
      "Epoch 606: perda treino: 1.2480523586273193\n",
      "Epoch 607: perda treino: 1.2435345649719238\n",
      "Epoch 608: perda treino: 1.2415549755096436\n",
      "Epoch 609: perda treino: 1.2376598119735718\n",
      "Epoch 610: perda treino: 1.2348347902297974\n",
      "Epoch 611: perda treino: 1.2307957410812378\n",
      "Epoch 612: perda treino: 1.228420376777649\n",
      "Epoch 613: perda treino: 1.2243099212646484\n",
      "Epoch 614: perda treino: 1.22189462184906\n",
      "Epoch 615: perda treino: 1.2177786827087402\n",
      "Epoch 616: perda treino: 1.2151907682418823\n",
      "Epoch 617: perda treino: 1.211341381072998\n",
      "Epoch 618: perda treino: 1.208838939666748\n",
      "Epoch 619: perda treino: 1.204949140548706\n",
      "Epoch 620: perda treino: 1.2024192810058594\n",
      "Epoch 621: perda treino: 1.1987900733947754\n",
      "Epoch 622: perda treino: 1.195642352104187\n",
      "Epoch 623: perda treino: 1.1922714710235596\n",
      "Epoch 624: perda treino: 1.188615083694458\n",
      "Epoch 625: perda treino: 1.185741901397705\n",
      "Epoch 626: perda treino: 1.1829373836517334\n",
      "Epoch 627: perda treino: 1.1790727376937866\n",
      "Epoch 628: perda treino: 1.175544261932373\n",
      "Epoch 629: perda treino: 1.1727591753005981\n",
      "Epoch 630: perda treino: 1.1697968244552612\n",
      "Epoch 631: perda treino: 1.1660058498382568\n",
      "Epoch 632: perda treino: 1.162509560585022\n",
      "Epoch 633: perda treino: 1.1597267389297485\n",
      "Epoch 634: perda treino: 1.1555930376052856\n",
      "Epoch 635: perda treino: 1.1532814502716064\n",
      "Epoch 636: perda treino: 1.1490353345870972\n",
      "Epoch 637: perda treino: 1.146691083908081\n",
      "Epoch 638: perda treino: 1.1425260305404663\n",
      "Epoch 639: perda treino: 1.140061378479004\n",
      "Epoch 640: perda treino: 1.1360633373260498\n",
      "Epoch 641: perda treino: 1.1333023309707642\n",
      "Epoch 642: perda treino: 1.1282743215560913\n",
      "Epoch 643: perda treino: 1.1249992847442627\n",
      "Epoch 644: perda treino: 1.1217732429504395\n",
      "Epoch 645: perda treino: 1.1180753707885742\n",
      "Epoch 646: perda treino: 1.1147600412368774\n",
      "Epoch 647: perda treino: 1.1131447553634644\n",
      "Epoch 648: perda treino: 1.1089857816696167\n",
      "Epoch 649: perda treino: 1.1053388118743896\n",
      "Epoch 650: perda treino: 1.1020383834838867\n",
      "Epoch 651: perda treino: 1.0988343954086304\n",
      "Epoch 652: perda treino: 1.0962841510772705\n",
      "Epoch 653: perda treino: 1.092516303062439\n",
      "Epoch 654: perda treino: 1.0893032550811768\n",
      "Epoch 655: perda treino: 1.086183786392212\n",
      "Epoch 656: perda treino: 1.0831329822540283\n",
      "Epoch 657: perda treino: 1.079498052597046\n",
      "Epoch 658: perda treino: 1.0764915943145752\n",
      "Epoch 659: perda treino: 1.072364091873169\n",
      "Epoch 660: perda treino: 1.069802165031433\n",
      "Epoch 661: perda treino: 1.0654410123825073\n",
      "Epoch 662: perda treino: 1.062208652496338\n",
      "Epoch 663: perda treino: 1.058319091796875\n",
      "Epoch 664: perda treino: 1.0549191236495972\n",
      "Epoch 665: perda treino: 1.050984263420105\n",
      "Epoch 666: perda treino: 1.0475759506225586\n",
      "Epoch 667: perda treino: 1.0435162782669067\n",
      "Epoch 668: perda treino: 1.0405946969985962\n",
      "Epoch 669: perda treino: 1.0371015071868896\n",
      "Epoch 670: perda treino: 1.033940076828003\n",
      "Epoch 671: perda treino: 1.0301628112792969\n",
      "Epoch 672: perda treino: 1.0264863967895508\n",
      "Epoch 673: perda treino: 1.0228952169418335\n",
      "Epoch 674: perda treino: 1.0188416242599487\n",
      "Epoch 675: perda treino: 1.0148791074752808\n",
      "Epoch 676: perda treino: 1.0108100175857544\n",
      "Epoch 677: perda treino: 1.0069804191589355\n",
      "Epoch 678: perda treino: 1.003513216972351\n",
      "Epoch 679: perda treino: 0.999449610710144\n",
      "Epoch 680: perda treino: 0.9955618977546692\n",
      "Epoch 681: perda treino: 0.9923878312110901\n",
      "Epoch 682: perda treino: 0.9883392453193665\n",
      "Epoch 683: perda treino: 0.9847990870475769\n",
      "Epoch 684: perda treino: 0.9818174242973328\n",
      "Epoch 685: perda treino: 0.9778994917869568\n",
      "Epoch 686: perda treino: 0.9746751189231873\n",
      "Epoch 687: perda treino: 0.9710443019866943\n",
      "Epoch 688: perda treino: 0.967359185218811\n",
      "Epoch 689: perda treino: 0.9644359946250916\n",
      "Epoch 690: perda treino: 0.960449755191803\n",
      "Epoch 691: perda treino: 0.9574035406112671\n",
      "Epoch 692: perda treino: 0.9540186524391174\n",
      "Epoch 693: perda treino: 0.9504662752151489\n",
      "Epoch 694: perda treino: 0.9474955201148987\n",
      "Epoch 695: perda treino: 0.94386225938797\n",
      "Epoch 696: perda treino: 0.9408761262893677\n",
      "Epoch 697: perda treino: 0.9374946355819702\n",
      "Epoch 698: perda treino: 0.9342566132545471\n",
      "Epoch 699: perda treino: 0.9311985373497009\n",
      "Epoch 700: perda treino: 0.9277712106704712\n",
      "Epoch 701: perda treino: 0.9247840642929077\n",
      "Epoch 702: perda treino: 0.9213826060295105\n",
      "Epoch 703: perda treino: 0.9182552099227905\n",
      "Epoch 704: perda treino: 0.9151278138160706\n",
      "Epoch 705: perda treino: 0.9118767380714417\n",
      "Epoch 706: perda treino: 0.9088644981384277\n",
      "Epoch 707: perda treino: 0.9056314826011658\n",
      "Epoch 708: perda treino: 0.9027830958366394\n",
      "Epoch 709: perda treino: 0.8997632265090942\n",
      "Epoch 710: perda treino: 0.8966569304466248\n",
      "Epoch 711: perda treino: 0.8937336802482605\n",
      "Epoch 712: perda treino: 0.890701174736023\n",
      "Epoch 713: perda treino: 0.887643575668335\n",
      "Epoch 714: perda treino: 0.8848621845245361\n",
      "Epoch 715: perda treino: 0.8825525045394897\n",
      "Epoch 716: perda treino: 0.8789173364639282\n",
      "Epoch 717: perda treino: 0.8766536712646484\n",
      "Epoch 718: perda treino: 0.8755471706390381\n",
      "Epoch 719: perda treino: 0.8702393770217896\n",
      "Epoch 720: perda treino: 0.8693318963050842\n",
      "Epoch 721: perda treino: 0.8673950433731079\n",
      "Epoch 722: perda treino: 0.8622778654098511\n",
      "Epoch 723: perda treino: 0.8619559407234192\n",
      "Epoch 724: perda treino: 0.8567253947257996\n",
      "Epoch 725: perda treino: 0.8557412624359131\n",
      "Epoch 726: perda treino: 0.8524116277694702\n",
      "Epoch 727: perda treino: 0.8484698534011841\n",
      "Epoch 728: perda treino: 0.8472341895103455\n",
      "Epoch 729: perda treino: 0.8429084420204163\n",
      "Epoch 730: perda treino: 0.8413643836975098\n",
      "Epoch 731: perda treino: 0.8376567363739014\n",
      "Epoch 732: perda treino: 0.8353669047355652\n",
      "Epoch 733: perda treino: 0.8330591320991516\n",
      "Epoch 734: perda treino: 0.829403281211853\n",
      "Epoch 735: perda treino: 0.8278961777687073\n",
      "Epoch 736: perda treino: 0.8246976733207703\n",
      "Epoch 737: perda treino: 0.8218203186988831\n",
      "Epoch 738: perda treino: 0.8199900984764099\n",
      "Epoch 739: perda treino: 0.8167353868484497\n",
      "Epoch 740: perda treino: 0.8143343329429626\n",
      "Epoch 741: perda treino: 0.8122302293777466\n",
      "Epoch 742: perda treino: 0.8091716170310974\n",
      "Epoch 743: perda treino: 0.8071668744087219\n",
      "Epoch 744: perda treino: 0.8044714331626892\n",
      "Epoch 745: perda treino: 0.8019886612892151\n",
      "Epoch 746: perda treino: 0.7997897863388062\n",
      "Epoch 747: perda treino: 0.7970488667488098\n",
      "Epoch 748: perda treino: 0.7948189377784729\n",
      "Epoch 749: perda treino: 0.7921324372291565\n",
      "Epoch 750: perda treino: 0.7898255586624146\n",
      "Epoch 751: perda treino: 0.7877392172813416\n",
      "Epoch 752: perda treino: 0.784998893737793\n",
      "Epoch 753: perda treino: 0.7826841473579407\n",
      "Epoch 754: perda treino: 0.7801063656806946\n",
      "Epoch 755: perda treino: 0.7776652574539185\n",
      "Epoch 756: perda treino: 0.7753593921661377\n",
      "Epoch 757: perda treino: 0.7730565667152405\n",
      "Epoch 758: perda treino: 0.7707580924034119\n",
      "Epoch 759: perda treino: 0.7683650255203247\n",
      "Epoch 760: perda treino: 0.7660492062568665\n",
      "Epoch 761: perda treino: 0.7646380066871643\n",
      "Epoch 762: perda treino: 0.761563777923584\n",
      "Epoch 763: perda treino: 0.7590622305870056\n",
      "Epoch 764: perda treino: 0.7567012310028076\n",
      "Epoch 765: perda treino: 0.7545567154884338\n",
      "Epoch 766: perda treino: 0.7522459626197815\n",
      "Epoch 767: perda treino: 0.7498193383216858\n",
      "Epoch 768: perda treino: 0.7475317716598511\n",
      "Epoch 769: perda treino: 0.7454673647880554\n",
      "Epoch 770: perda treino: 0.7430734038352966\n",
      "Epoch 771: perda treino: 0.7407443523406982\n",
      "Epoch 772: perda treino: 0.738568127155304\n",
      "Epoch 773: perda treino: 0.7364149689674377\n",
      "Epoch 774: perda treino: 0.7343221306800842\n",
      "Epoch 775: perda treino: 0.7320664525032043\n",
      "Epoch 776: perda treino: 0.7299103140830994\n",
      "Epoch 777: perda treino: 0.7277925610542297\n",
      "Epoch 778: perda treino: 0.7255958318710327\n",
      "Epoch 779: perda treino: 0.7235665321350098\n",
      "Epoch 780: perda treino: 0.7216683626174927\n",
      "Epoch 781: perda treino: 0.7193700671195984\n",
      "Epoch 782: perda treino: 0.7173110842704773\n",
      "Epoch 783: perda treino: 0.7155860662460327\n",
      "Epoch 784: perda treino: 0.7133796811103821\n",
      "Epoch 785: perda treino: 0.7110838294029236\n",
      "Epoch 786: perda treino: 0.7091454863548279\n",
      "Epoch 787: perda treino: 0.7074394226074219\n",
      "Epoch 788: perda treino: 0.7061935663223267\n",
      "Epoch 789: perda treino: 0.7039042115211487\n",
      "Epoch 790: perda treino: 0.7018525004386902\n",
      "Epoch 791: perda treino: 0.6995450854301453\n",
      "Epoch 792: perda treino: 0.6979197859764099\n",
      "Epoch 793: perda treino: 0.6960802674293518\n",
      "Epoch 794: perda treino: 0.6940184831619263\n",
      "Epoch 795: perda treino: 0.6924115419387817\n",
      "Epoch 796: perda treino: 0.6905255913734436\n",
      "Epoch 797: perda treino: 0.6885519623756409\n",
      "Epoch 798: perda treino: 0.6869905591011047\n",
      "Epoch 799: perda treino: 0.6853749752044678\n",
      "Epoch 800: perda treino: 0.6831516623497009\n",
      "Epoch 801: perda treino: 0.6811313033103943\n",
      "Epoch 802: perda treino: 0.6792657971382141\n",
      "Epoch 803: perda treino: 0.6775627732276917\n",
      "Epoch 804: perda treino: 0.6755892038345337\n",
      "Epoch 805: perda treino: 0.6736418604850769\n",
      "Epoch 806: perda treino: 0.672135591506958\n",
      "Epoch 807: perda treino: 0.6703014373779297\n",
      "Epoch 808: perda treino: 0.668116569519043\n",
      "Epoch 809: perda treino: 0.6663535833358765\n",
      "Epoch 810: perda treino: 0.6647838950157166\n",
      "Epoch 811: perda treino: 0.6628143191337585\n",
      "Epoch 812: perda treino: 0.6608860492706299\n",
      "Epoch 813: perda treino: 0.6592132449150085\n",
      "Epoch 814: perda treino: 0.6576572060585022\n",
      "Epoch 815: perda treino: 0.6568689942359924\n",
      "Epoch 816: perda treino: 0.6547664403915405\n",
      "Epoch 817: perda treino: 0.6524712443351746\n",
      "Epoch 818: perda treino: 0.6507620811462402\n",
      "Epoch 819: perda treino: 0.6495269536972046\n",
      "Epoch 820: perda treino: 0.6476923227310181\n",
      "Epoch 821: perda treino: 0.6457820534706116\n",
      "Epoch 822: perda treino: 0.6443675756454468\n",
      "Epoch 823: perda treino: 0.6428223252296448\n",
      "Epoch 824: perda treino: 0.6409786939620972\n",
      "Epoch 825: perda treino: 0.6394727230072021\n",
      "Epoch 826: perda treino: 0.6381521224975586\n",
      "Epoch 827: perda treino: 0.6364710927009583\n",
      "Epoch 828: perda treino: 0.6348207592964172\n",
      "Epoch 829: perda treino: 0.6332256197929382\n",
      "Epoch 830: perda treino: 0.6316884756088257\n",
      "Epoch 831: perda treino: 0.6302036643028259\n",
      "Epoch 832: perda treino: 0.6287112832069397\n",
      "Epoch 833: perda treino: 0.6272973418235779\n",
      "Epoch 834: perda treino: 0.6261981725692749\n",
      "Epoch 835: perda treino: 0.6245833039283752\n",
      "Epoch 836: perda treino: 0.6232262849807739\n",
      "Epoch 837: perda treino: 0.6211205720901489\n",
      "Epoch 838: perda treino: 0.6193807125091553\n",
      "Epoch 839: perda treino: 0.6178638935089111\n",
      "Epoch 840: perda treino: 0.6163827180862427\n",
      "Epoch 841: perda treino: 0.6149156093597412\n",
      "Epoch 842: perda treino: 0.6131522059440613\n",
      "Epoch 843: perda treino: 0.6115410923957825\n",
      "Epoch 844: perda treino: 0.6101717352867126\n",
      "Epoch 845: perda treino: 0.6086381077766418\n",
      "Epoch 846: perda treino: 0.6070739030838013\n",
      "Epoch 847: perda treino: 0.6054139137268066\n",
      "Epoch 848: perda treino: 0.603863537311554\n",
      "Epoch 849: perda treino: 0.6024810671806335\n",
      "Epoch 850: perda treino: 0.6009759306907654\n",
      "Epoch 851: perda treino: 0.5994639992713928\n",
      "Epoch 852: perda treino: 0.5979494452476501\n",
      "Epoch 853: perda treino: 0.596355140209198\n",
      "Epoch 854: perda treino: 0.594934344291687\n",
      "Epoch 855: perda treino: 0.5936015844345093\n",
      "Epoch 856: perda treino: 0.5922932028770447\n",
      "Epoch 857: perda treino: 0.5907270312309265\n",
      "Epoch 858: perda treino: 0.5890163779258728\n",
      "Epoch 859: perda treino: 0.5873997211456299\n",
      "Epoch 860: perda treino: 0.5861278176307678\n",
      "Epoch 861: perda treino: 0.5853755474090576\n",
      "Epoch 862: perda treino: 0.5841509103775024\n",
      "Epoch 863: perda treino: 0.582048237323761\n",
      "Epoch 864: perda treino: 0.5804639458656311\n",
      "Epoch 865: perda treino: 0.5795845985412598\n",
      "Epoch 866: perda treino: 0.5783016681671143\n",
      "Epoch 867: perda treino: 0.5765370726585388\n",
      "Epoch 868: perda treino: 0.5750365257263184\n",
      "Epoch 869: perda treino: 0.5737197399139404\n",
      "Epoch 870: perda treino: 0.5723339915275574\n",
      "Epoch 871: perda treino: 0.5706799626350403\n",
      "Epoch 872: perda treino: 0.5689414739608765\n",
      "Epoch 873: perda treino: 0.567441999912262\n",
      "Epoch 874: perda treino: 0.5660105347633362\n",
      "Epoch 875: perda treino: 0.5645176768302917\n",
      "Epoch 876: perda treino: 0.562863826751709\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 877: perda treino: 0.561084508895874\n",
      "Epoch 878: perda treino: 0.5593702793121338\n",
      "Epoch 879: perda treino: 0.5576016306877136\n",
      "Epoch 880: perda treino: 0.5558968782424927\n",
      "Epoch 881: perda treino: 0.5543555021286011\n",
      "Epoch 882: perda treino: 0.5528401136398315\n",
      "Epoch 883: perda treino: 0.5512795448303223\n",
      "Epoch 884: perda treino: 0.5499662160873413\n",
      "Epoch 885: perda treino: 0.5494145154953003\n",
      "Epoch 886: perda treino: 0.5487712621688843\n",
      "Epoch 887: perda treino: 0.5477101802825928\n",
      "Epoch 888: perda treino: 0.5461524724960327\n",
      "Epoch 889: perda treino: 0.5447512865066528\n",
      "Epoch 890: perda treino: 0.5436328053474426\n",
      "Epoch 891: perda treino: 0.5429383516311646\n",
      "Epoch 892: perda treino: 0.542476236820221\n",
      "Epoch 893: perda treino: 0.542234480381012\n",
      "Epoch 894: perda treino: 0.5415703654289246\n",
      "Epoch 895: perda treino: 0.5421638488769531\n",
      "Epoch 896: perda treino: 0.5412397384643555\n",
      "Epoch 897: perda treino: 0.5410507917404175\n",
      "Epoch 898: perda treino: 0.5383231043815613\n",
      "Epoch 899: perda treino: 0.5360589027404785\n",
      "Epoch 900: perda treino: 0.5358405113220215\n",
      "Epoch 901: perda treino: 0.5362992286682129\n",
      "Epoch 902: perda treino: 0.5354059934616089\n",
      "Epoch 903: perda treino: 0.5333951711654663\n",
      "Epoch 904: perda treino: 0.5319485664367676\n",
      "Epoch 905: perda treino: 0.532015860080719\n",
      "Epoch 906: perda treino: 0.5319523215293884\n",
      "Epoch 907: perda treino: 0.5309067964553833\n",
      "Epoch 908: perda treino: 0.5292297601699829\n",
      "Epoch 909: perda treino: 0.5284078121185303\n",
      "Epoch 910: perda treino: 0.5283058285713196\n",
      "Epoch 911: perda treino: 0.5278385877609253\n",
      "Epoch 912: perda treino: 0.5266329050064087\n",
      "Epoch 913: perda treino: 0.5254768133163452\n",
      "Epoch 914: perda treino: 0.524978518486023\n",
      "Epoch 915: perda treino: 0.5246521830558777\n",
      "Epoch 916: perda treino: 0.5239051580429077\n",
      "Epoch 917: perda treino: 0.5228009819984436\n",
      "Epoch 918: perda treino: 0.5220018625259399\n",
      "Epoch 919: perda treino: 0.5216756463050842\n",
      "Epoch 920: perda treino: 0.5212675929069519\n",
      "Epoch 921: perda treino: 0.5204415321350098\n",
      "Epoch 922: perda treino: 0.5194553732872009\n",
      "Epoch 923: perda treino: 0.5188195109367371\n",
      "Epoch 924: perda treino: 0.5186893343925476\n",
      "Epoch 925: perda treino: 0.5189149975776672\n",
      "Epoch 926: perda treino: 0.5186066627502441\n",
      "Epoch 927: perda treino: 0.5176852941513062\n",
      "Epoch 928: perda treino: 0.5163537263870239\n",
      "Epoch 929: perda treino: 0.5152906775474548\n",
      "Epoch 930: perda treino: 0.5146464705467224\n",
      "Epoch 931: perda treino: 0.5141317248344421\n",
      "Epoch 932: perda treino: 0.5137006640434265\n",
      "Epoch 933: perda treino: 0.5131500363349915\n",
      "Epoch 934: perda treino: 0.512542188167572\n",
      "Epoch 935: perda treino: 0.5118788480758667\n",
      "Epoch 936: perda treino: 0.5112724900245667\n",
      "Epoch 937: perda treino: 0.5107132196426392\n",
      "Epoch 938: perda treino: 0.5102165937423706\n",
      "Epoch 939: perda treino: 0.5097079873085022\n",
      "Epoch 940: perda treino: 0.5092071294784546\n",
      "Epoch 941: perda treino: 0.5086615085601807\n",
      "Epoch 942: perda treino: 0.5081014633178711\n",
      "Epoch 943: perda treino: 0.5076469779014587\n",
      "Epoch 944: perda treino: 0.5071275234222412\n",
      "Epoch 945: perda treino: 0.5065856575965881\n",
      "Epoch 946: perda treino: 0.5061174631118774\n",
      "Epoch 947: perda treino: 0.5057042241096497\n",
      "Epoch 948: perda treino: 0.5053867697715759\n",
      "Epoch 949: perda treino: 0.5053258538246155\n",
      "Epoch 950: perda treino: 0.5053440928459167\n",
      "Epoch 951: perda treino: 0.5051355957984924\n",
      "Epoch 952: perda treino: 0.5045875906944275\n",
      "Epoch 953: perda treino: 0.5033828020095825\n",
      "Epoch 954: perda treino: 0.5023659467697144\n",
      "Epoch 955: perda treino: 0.5020878911018372\n",
      "Epoch 956: perda treino: 0.5021392703056335\n",
      "Epoch 957: perda treino: 0.5018653869628906\n",
      "Epoch 958: perda treino: 0.5011227130889893\n",
      "Epoch 959: perda treino: 0.5002561211585999\n",
      "Epoch 960: perda treino: 0.4996826648712158\n",
      "Epoch 961: perda treino: 0.49932703375816345\n",
      "Epoch 962: perda treino: 0.49901679158210754\n",
      "Epoch 963: perda treino: 0.49858224391937256\n",
      "Epoch 964: perda treino: 0.4980506896972656\n",
      "Epoch 965: perda treino: 0.49751874804496765\n",
      "Epoch 966: perda treino: 0.49705958366394043\n",
      "Epoch 967: perda treino: 0.4967356026172638\n",
      "Epoch 968: perda treino: 0.49654698371887207\n",
      "Epoch 969: perda treino: 0.4961695969104767\n",
      "Epoch 970: perda treino: 0.49559125304222107\n",
      "Epoch 971: perda treino: 0.49502214789390564\n",
      "Epoch 972: perda treino: 0.4945630133152008\n",
      "Epoch 973: perda treino: 0.4942259192466736\n",
      "Epoch 974: perda treino: 0.4943975806236267\n",
      "Epoch 975: perda treino: 0.49442607164382935\n",
      "Epoch 976: perda treino: 0.4940994381904602\n",
      "Epoch 977: perda treino: 0.49415168166160583\n",
      "Epoch 978: perda treino: 0.49337026476860046\n",
      "Epoch 979: perda treino: 0.49277135729789734\n",
      "Epoch 980: perda treino: 0.49224504828453064\n",
      "Epoch 981: perda treino: 0.49172472953796387\n",
      "Epoch 982: perda treino: 0.490928590297699\n",
      "Epoch 983: perda treino: 0.4902257025241852\n",
      "Epoch 984: perda treino: 0.4896638095378876\n",
      "Epoch 985: perda treino: 0.489282488822937\n",
      "Epoch 986: perda treino: 0.4893514811992645\n",
      "Epoch 987: perda treino: 0.4892314374446869\n",
      "Epoch 988: perda treino: 0.48930490016937256\n",
      "Epoch 989: perda treino: 0.48916804790496826\n",
      "Epoch 990: perda treino: 0.48867934942245483\n",
      "Epoch 991: perda treino: 0.4879216253757477\n",
      "Epoch 992: perda treino: 0.4870128035545349\n",
      "Epoch 993: perda treino: 0.48632028698921204\n",
      "Epoch 994: perda treino: 0.48586609959602356\n",
      "Epoch 995: perda treino: 0.48558181524276733\n",
      "Epoch 996: perda treino: 0.48533156514167786\n",
      "Epoch 997: perda treino: 0.4852181673049927\n",
      "Epoch 998: perda treino: 0.4849127531051636\n",
      "Epoch 999: perda treino: 0.48438894748687744\n",
      "Teste - perda depois do treinamento 0.7467465400695801\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "y_pred = model(X_teste)\n",
    "antes_treino = criterion(y_pred, y_teste) \n",
    "print('Teste - perda antes do treinamento' , antes_treino.item())\n",
    "\n",
    "\n",
    "#-----------------Treinamento\n",
    "model.train()\n",
    "epoch = 1000\n",
    "\n",
    "for epoch in range(epoch):\n",
    "    \n",
    "    #Explicitamente configura os gradientes em zero\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # Passe Forward\n",
    "    y_pred = model(X_treino)\n",
    "    \n",
    "    # Computa a perda\n",
    "    loss = criterion(y_pred, y_treino)\n",
    "    \n",
    "    print('Epoch {}: perda treino: {}'.format(epoch, loss.item()))\n",
    "    \n",
    "    # Propaga os erros (backpropagation) e atualiza os pesos\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    \n",
    "    \n",
    "#-----------------Avaliação\n",
    "model.eval()\n",
    "\n",
    "y_pred = model(X_teste)\n",
    "after_train = criterion(y_pred, y_teste) \n",
    "print('Teste - perda depois do treinamento' , after_train.item())    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gnn",
   "language": "python",
   "name": "gnn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
